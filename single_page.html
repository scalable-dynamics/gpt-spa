<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>gpt-spa - Scalable Dynamics</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            height: 100%;
            background-color: #f2f2f2;
        }

        .toolbar {
            display: none;
            align-items: center;
            white-space: nowrap;
            background-color: #f8f8f8;
            flex-wrap: wrap;
        }

        body.ready .toolbar {
            display: flex;
            position: fixed;
            inset: 8px;
            bottom: auto;
        }

        .toolbar button {
            margin: 0 7px;
        }

        .toolbar label {
            margin: 8px 7px;
        }

        #gpt-button {
            background-color: transparent;
            border: none;
            cursor: pointer;
            padding: 10px 20px;
            font-size: 16px;
            margin: 20px 0;
        }

        #search {
            padding: 10px;
            font-size: 16px;
            margin: 20px 0;
            flex-grow: 20;
        }

        #search-button,
        #ask-button,
        .ac-pushButton {
            padding: 10px 20px;
            font-size: 16px;
            background-color: #4CAF50;
            color: white;
            border: none;
            cursor: pointer;
        }

        #search-button:hover {
            background-color: #45a049;
        }

        #ask-button,
        .ac-pushButton {
            background-color: #2196F3;
        }

        #ask-button:hover,
        .ac-pushButton:hover {
            background-color: #0b7dda;
        }

        .ac-textInput {
            border: 1px solid #ccc;
            border-radius: 4px;
            padding: 10px;
            font-size: 16px;
            width: 100%;
        }

        #output-container {
            width: 70%;
        }

        .file-name {
            font-size: 18px;
            color: #333;
            background-color: #f8f8f8;
            padding: 10px;
            border-radius: 5px;
            border: 1px solid #ddd;
            margin-bottom: 10px;
        }

        .output-message {
            background-color: #f8f8f8;
            padding: 10px;
            border-radius: 5px;
            border: 1px solid #ddd;
            margin-bottom: 10px;
        }

        .output-message h3 {
            margin: 0;
            font-size: 16px;
            color: #333;
        }

        .output-message p {
            margin: 0;
            font-size: 14px;
            color: #555;
        }

        #output-container img {
            max-width: 256px;
        }

        .loader {
            display: inline-block;
            position: relative;
            width: 80px;
            height: 80px;
        }

        .loader div {
            position: absolute;
            top: 33px;
            width: 13px;
            height: 13px;
            border-radius: 50%;
            background: black;
            animation-timing-function: cubic-bezier(0, 1, 1, 0);
        }

        .loader div:nth-child(1) {
            left: 8px;
            animation: loader1 0.6s infinite;
        }

        .loader div:nth-child(2) {
            left: 8px;
            animation: loader2 0.6s infinite;
        }

        .loader div:nth-child(3) {
            left: 32px;
            animation: loader2 0.6s infinite;
        }

        .loader div:nth-child(4) {
            left: 56px;
            animation: loader3 0.6s infinite;
        }

        @keyframes loader1 {
            0% {
                transform: scale(0);
            }
        }

        @keyframes loader3 {
            0% {
                transform: scale(0);
            }

            100% {
                transform: scale(1);
            }
        }

        @keyframes loader2 {
            0% {
                transform: translate(0, 0);
            }

            100% {
                transform: translate(24px, 0);
            }
        }

        @media screen and (max-width: 600px) {
            #search {
                width: 100%;
            }

            #output-container {
                width: 100%;
                top: 0;
            }
        }
    </style>
</head>

<body>
    <div class="toolbar">
        <button id="gpt-button" title="Change GPT system prompt">⬆️</button>
        <input id="search" type="text" placeholder="Enter prompt or drop files here..." />
        <button id="ask-button">Ask</button>
        <button id="search-button">Search</button>
        <label>
            <input type="checkbox" id="use-files" checked />
            Use files
        </label>
        <label>
            <input type="checkbox" id="use-dalle" />
            Use DALL-E
        </label>
        <label>
            <input type="checkbox" id="use-speech" />
            Use Speech
        </label>
        <select id="voice-list">
            <option value="alloy" selected>Alloy</option>
            <option value="echo">Echo</option>
            <option value="fable">Fable</option>
            <option value="onyx">Onyx</option>
            <option value="nova">Nova</option>
            <option value="shimmer">Shimmer</option>
        </select>
    </div>
    <div id="output-container"></div>
    <script src="https://unpkg.com/adaptivecards/dist/adaptivecards.min.js"></script>
    <script src="https://unpkg.com/markdown-it/dist/markdown-it.js"></script>
    <script type="module">
        import * as pdfjsLib from 'https://mozilla.github.io/pdf.js/build/pdf.mjs';
        pdfjsLib.GlobalWorkerOptions.workerSrc = 'https://mozilla.github.io/pdf.js/build/pdf.worker.mjs';

        useMarkdownRenderer(renderMarkdown)

        const welcomeMessage = "Hello, how can I assist you today?"
        const gptName = "GPT"
        const toolbar = document.getElementsByClassName('toolbar')[0];
        const searchInput = document.getElementById('search');
        const gptButton = document.getElementById('gpt-button');
        const searchButton = document.getElementById('search-button');
        const askButton = document.getElementById('ask-button');
        const outputContainer = document.getElementById('output-container');
        const useFiles = document.getElementById('use-files');
        const useDalle = document.getElementById('use-dalle');
        const useSpeech = document.getElementById('use-speech');
        const voiceList = document.getElementById('voice-list');
        const OPENAI_API_KEY = await getConfig('OPENAI_API_KEY')
        const OPENAI_API_ORG = await getConfig('OPENAI_API_ORG')
        const openai_headers = {
            "Authorization": `Bearer ${OPENAI_API_KEY}`
        };
        if (OPENAI_API_ORG && OPENAI_API_ORG !== '--none--') {
            openai_headers["OpenAI-Organization"] = OPENAI_API_ORG
        } else if (OPENAI_API_KEY) {
            localStorage.setItem('OPENAI_API_ORG', '--none--')
        }

        let sys_prompt = await getConfig('SYSTEM_PROMPT', 'Enter the system prompt for your GPT:', 'You are a helpful assistant.')
        if (!sys_prompt) {
            addOutput('No system prompt provided, please refresh the page to try again.', gptName)
            throw new Error('No system prompt provided, please refresh the page to try again.')
        }
        let conversation = createConversation(sys_prompt)
        let userImages = []

        addOutput(welcomeMessage, gptName)

        document.body.classList.add('ready');
        outputContainer.style.marginTop = `${toolbar.clientHeight + 20}px`;
        searchButton.addEventListener('click', getSearchResults);
        askButton.addEventListener('click', askAssistant);
        searchInput.addEventListener('keyup', (e) => {
            if (e.key === 'Enter') {
                askAssistant();
            }
        });
        gptButton.addEventListener('click', () => {
            const confirm = confirmationCard('Are you sure you want to reset the system prompt?')
            outputContainer.appendChild(confirm.render())
            confirm.getAnswer().then(async (confirmation) => {
                if (confirmation) {
                    outputContainer.innerHTML = ''
                    sys_prompt = localStorage.getItem('SYSTEM_PROMPT')
                    localStorage.removeItem('SYSTEM_PROMPT')
                    document.body.classList.remove('ready');
                    const prompt = await getConfig('SYSTEM_PROMPT', 'Enter the system prompt for your GPT:', sys_prompt)
                    if (prompt) {
                        sys_prompt = prompt
                        localStorage.setItem('SYSTEM_PROMPT', prompt)
                        conversation = createConversation(prompt)
                        addOutput(welcomeMessage, gptName)
                        document.body.classList.add('ready')
                    } else {
                        addOutput('No system prompt provided, please refresh the page to try again.', gptName)
                    }
                }
            })
        })

        onFilesDropped(document.body, async (files) => {
            for (let i = 0; i < files.length; i++) {
                const { name, type, content } = files[i];
                if (content.trim()) {
                    if (type.indexOf('image') === 0) {
                        addImage(content);
                    } else {
                        await conversation.add(name, content);
                        addOutput(`Added ${name}`, gptName);
                    }
                }
            }
        });

        function renderMarkdown(text) {
            const md = markdownit();
            return md.render(text);
        }

        function addImage(url) {
            const img = document.createElement('img');
            img.src = url;
            outputContainer.appendChild(img);
            userImages.push(url);
            return img;
        }

        function addOutput(content, sender) {
            const loading = `<div class="loader"><div></div><div></div><div></div><div></div></div>`
            const container = document.createElement('div');
            container.className = 'output-message';
            container.innerHTML = `<h3>${sender}</h3>`;
            outputContainer.appendChild(container);
            const card = contentCard(content || " ");
            container.appendChild(card);
            let message = card.querySelector('.ac-textBlock')
            if (!content) {
                message.innerHTML = loading
            }
            return (text, replace) => {
                if (!content) {
                    message.innerHTML = ""
                }
                if (text instanceof HTMLImageElement) {
                    message.innerHTML = ""
                    message.appendChild(text)
                } else if (replace) {
                    message.innerHTML = renderMarkdown((content = text))
                } else {
                    message.innerHTML = renderMarkdown((content += text))
                }
            }
        }

        async function askAssistant() {
            let input = searchInput.value;
            if (!input) return;
            searchInput.value = '';
            addOutput(input, 'You');
            if (userImages.length > 0) {
                input = [
                    {
                        type: 'text',
                        text: input
                    },
                    ...userImages.slice(0, 5).map(image => ({
                        type: 'image',
                        image_url: image
                    }))
                ]
                userImages = []
            }
            const appendOutput = addOutput("", gptName)
            if (useDalle.checked) {
                const image = await conversation.send(input, undefined, useFiles.checked, true);
                if (image) {
                    appendOutput(addImage(image))
                }
            } else {
                const result = await conversation.send(input, appendOutput, useFiles.checked);
                if (useSpeech.checked) {
                    await conversation.speech(result, voiceList.value);
                }
            }
        }

        async function getSearchResults() {
            const query = searchInput.value;
            if (!query) return;
            outputContainer.innerHTML = '';
            const results = await conversation.search(query);
            addOutput(`Found ${results.length} results for "${query}"`, gptName);
            for (const { name, text, relevance } of results) {
                addOutput(text, `${name} (${relevance.toFixed(2)})`);
            }
        }

        function createConversation(systemPrompt) {
            const embeddingsDB = [];
            const messages = [{ role: "system", content: systemPrompt }];
            return {
                async send(content, onTextReceived = undefined, useVectorSearch = false, generateImage = false) {
                    const useVision = Array.isArray(content)
                    if (useVectorSearch) {
                        const results = await this.search(useVision ? content[0].text : content);
                        if (results.length > 0) {
                            const retrieval = results[0].text;
                            messages.push({ content: `More details: ${retrieval}`, role: 'user' });
                        }
                    }
                    messages.push({ content, role: 'user' });
                    if (generateImage) {
                        messages.push({ content: 'Create a prompt for DALL-E to generate an image. Only return the prompt, NO OTHER TEXT.', role: 'user' });
                    }
                    const response = await get_completion(onTextReceived, useVision);
                    messages.push({ content: response, role: 'assistant' });
                    if (generateImage) {
                        return await get_image(response);
                    } else {
                        return response;
                    }
                },
                async search(text) {
                    const embeddings = await get_vectors([text]);
                    const single = embeddings[0];
                    if (!single) return [];
                    const results = retrieve_vectors(single.embedding);
                    return results;
                },
                async transcript(audioBlob) {
                    return await get_transcription(audioBlob);
                },
                async speech(text, voice) {
                    return await play_speech(text, voice);
                },
                async add(name, text) {
                    for (const chunk of chunk_text(text, 500)) {
                        if (chunk.length == 0) break;
                        if (!chunk.join('').trim()) break;
                        const embeddings = await get_vectors(chunk);
                        for (const { embedding, text } of embeddings) {
                            store_vector(name, text, embedding);
                        }
                    }
                }
            };

            async function get_completion(onTextReceived = undefined, useVision = false, max_tokens = 150) {
                const response = await fetch("https://api.openai.com/v1/chat/completions", {
                    headers: {
                        ...openai_headers,
                        'Content-Type': 'application/json'
                    },
                    method: 'POST',
                    body: JSON.stringify({
                        //TODO: not working with successive requests (since image content gets added to the messages), but acording to sama its the 'same'
                        //model: useVision ? 'gpt-4-vision-preview' : 'gpt-4-1106-preview',
                        model: 'gpt-4-vision-preview',
                        messages,
                        max_tokens,
                        temperature: 0.1,
                        top_p: 1,
                        stream: (onTextReceived !== undefined)
                    })
                })
                if (onTextReceived) {
                    if (!response.ok) throw new Error(await response.text());
                    if (!response.body[Symbol.asyncIterator]) {
                        response.body[Symbol.asyncIterator] = () => {
                            const reader = response.body.getReader();
                            return {
                                next: () => reader.read(),
                            };
                        };
                    }
                    let all_text = ""
                    const decoder = new TextDecoder()
                    for await (const chunk_arr of response.body) {
                        const chunk = decoder.decode(chunk_arr, { stream: true })
                        const lines = chunk.toString().trim().split("\n")
                        for (let line of lines) {
                            const data = line.indexOf('{')
                            if (data > -1) {
                                const json = line.slice(data);
                                if (json) {
                                    try {
                                        const data = JSON.parse(json);
                                        if (data.choices && data.choices.length > 0) {
                                            if (data.choices[0].finish_reason === "length" && max_tokens < 1000) {
                                                onTextReceived("", true)
                                                return await get_completion(onTextReceived, useVision, max_tokens * 2)
                                            }
                                            const text = data.choices[0].delta.content;
                                            if (!text) continue;
                                            all_text += text;
                                            onTextReceived(text);
                                        }
                                    } catch (e) {
                                        console.error(e)
                                        //TODO: handle this better
                                    }
                                }
                            }
                        }
                    }
                    return all_text
                } else {
                    const data = await response.json()
                    if (data && data.choices && data.choices[0] && data.choices[0].finish_reason === "length" && max_tokens < 1000) {
                        return await get_completion(onTextReceived, useVision, max_tokens * 2)
                    }
                    else if (data && data.choices && data.choices[0] && data.choices[0].message && data.choices[0].message.content) {
                        return data.choices[0].message.content.trim()
                    } else {
                        return ""
                    }
                }
            }

            async function get_image(prompt) {
                const response = await fetch("https://api.openai.com/v1/images/generations", {
                    headers: {
                        ...openai_headers,
                        'Content-Type': 'application/json'
                    },
                    method: 'POST',
                    body: JSON.stringify({
                        prompt,
                        model: 'dall-e-3',
                        size: '1024x1024',
                        n: 1
                    })
                })
                const image = await response.json()
                if (image && image.data && image.data[0] && image.data[0].url) {
                    return image.data[0].url
                }
            }

            async function play_speech(input, voice = 'alloy') {
                const response = await fetch("https://api.openai.com/v1/audio/speech", {
                    headers: {
                        ...openai_headers,
                        'Content-Type': 'application/json'
                    },
                    method: 'POST',
                    body: JSON.stringify({
                        input,
                        voice,
                        model: 'tts-1'
                    })
                })
                const audioData = [];
                const reader = response.body.getReader();
                const audioObj = new Audio();

                reader.read().then(function processAudio({ done, value }) {
                    if (done) {
                        audioObj.src = URL.createObjectURL(new Blob(audioData));
                        audioObj.play();
                        document.body.onclick = () => {
                            audioObj.pause();
                            document.body.onclick = undefined;
                        }
                        return;
                    }
                    audioData.push(value);
                    return reader.read().then(processAudio);
                });
            }

            async function get_transcription(audioBlob) {
                const formData = new FormData();
                formData.append('file', audioBlob, 'recording.webm');
                formData.append('model', 'whisper-1');
                const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
                    headers: openai_headers,
                    method: 'POST',
                    body: formData
                })
                const data = await response.json()
                return data.text
            }

            async function get_vectors(input) {
                const response = await fetch("https://api.openai.com/v1/embeddings", {
                    headers: {
                        ...openai_headers,
                        'Content-Type': 'application/json'
                    },
                    method: 'POST',
                    body: JSON.stringify({
                        input,
                        model: 'text-embedding-ada-002'
                    })
                })
                const embeddings = await response.json()
                if (embeddings && embeddings.data) {
                    return input.map((input, i) => ({
                        embedding: embeddings.data[i].embedding,
                        text: input
                    }))
                } else {
                    return []
                }
            }

            function store_vector(name, text, embedding) {
                embeddingsDB.push({ name, text, embedding });
            }

            function retrieve_vectors(target_embedding, count = 5) {
                const results = embeddingsDB.map(({ name, text, embedding }) => ({
                    name,
                    text,
                    relevance: cosine_similarity(embedding, target_embedding),
                })).slice(0, count);
                results.sort((a, b) => b.relevance - a.relevance);
                return results;
            }

            function cosine_similarity(vecA, vecB) {
                let dotProduct = 0.0, normA = 0.0, normB = 0.0;
                for (let i = 0; i < vecA.length; i++) {
                    dotProduct += vecA[i] * vecB[i];
                    normA += vecA[i] * vecA[i];
                    normB += vecB[i] * vecB[i];
                }
                if (normA === 0 || normB === 0) return 0;
                return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
            }

            function* chunk_text(text, maxChunkSize) {
                const sentences = text.match(/[^.!?]+[.!?]*/g) || [text];
                let chunk = '';
                let batch = [];
                const maxBatchSize = 20;

                for (let sentence of sentences) {
                    sentence = sentence.trim();
                    if ((chunk + ' ' + sentence).length <= maxChunkSize) {
                        chunk += ' ' + sentence;
                    } else {
                        if (chunk.trim()) {
                            batch.push(chunk.trim());
                            if (batch.length === maxBatchSize) {
                                yield batch;
                                batch = [];
                            }
                        }
                        chunk = sentence;
                    }
                }

                if (chunk.trim()) {
                    batch.push(chunk.trim());
                }

                if (batch.length) {
                    yield batch;
                }
            }
        }

        function onFilesDropped(element, onFilesAdded) {
            element.addEventListener('dragover', prevent_defaults, false);
            element.addEventListener('dragenter', prevent_defaults, false);
            element.addEventListener('drop', async (e) => {
                prevent_defaults(e);
                const contents = [];
                let files = e.dataTransfer.files;
                for (let i = 0; i < files.length; i++) {
                    const name = files[i].name;
                    const type = files[i].type;
                    try {
                        if (type === 'application/pdf') {
                            contents.push({
                                name,
                                type,
                                content: await read_pdf(files[i])
                            });
                        } else if (type.indexOf('image') === 0) {
                            contents.push({
                                name,
                                type,
                                content: await read_image(files[i])
                            })
                        } else {
                            contents.push({
                                name,
                                type,
                                content: await read_file(files[i])
                            });
                        }
                    } catch (e) {
                        console.error('FileReader error: ', e);
                        alert(`Error reading file ${name}`)
                    }
                }
                onFilesAdded(contents);
            }, false);

            function read_file(file) {
                return new Promise((resolve, reject) => {
                    const reader = new FileReader();
                    reader.onload = (event) => {
                        resolve(event.target.result);
                    };
                    reader.onerror = reject;
                    reader.readAsText(file);
                });
            }

            function read_image(file) {
                return new Promise((resolve, reject) => {
                    const reader = new FileReader();
                    reader.onloadend = function () {
                        resolve(reader.result);
                    }
                    reader.onerror = reject;
                    reader.readAsDataURL(file);
                });
            }

            function read_pdf(file) {
                return new Promise((resolve, reject) => {
                    const reader = new FileReader();
                    reader.onload = async (event) => {
                        try {
                            const pdfData = new Uint8Array(reader.result);
                            const pdfDoc = await pdfjsLib.getDocument({ data: pdfData }).promise;
                            let content = "";
                            for (let i = 1; i <= pdfDoc.numPages; i++) {
                                const page = await pdfDoc.getPage(i);
                                const textContent = await page.getTextContent();
                                content += textContent.items.map(item => item.str).join(" ");
                            }
                            resolve(content);
                        } catch (error) {
                            reject(error);
                        }
                    };
                    reader.onerror = reject;
                    reader.readAsArrayBuffer(file);
                });
            }

            function prevent_defaults(e) {
                e.preventDefault();
                e.stopPropagation();
            }
        }

        function contentCard(content) {
            const card = {
                type: 'AdaptiveCard',
                version: '1.5',
                body: [{
                    type: 'TextBlock',
                    text: content,
                    wrap: true
                }]
            }
            const adaptiveCard = new AdaptiveCards.AdaptiveCard();
            adaptiveCard.parse(card);
            return adaptiveCard.render();
        }

        function confirmationCard(message) {
            const card = {
                type: 'AdaptiveCard',
                version: '1.5',
                body: [{
                    type: 'TextBlock',
                    text: message,
                    wrap: true
                }],
                actions: [{
                    type: 'Action.Submit',
                    title: 'Yes',
                    data: 'yes'
                }, {
                    type: 'Action.Submit',
                    title: 'No',
                    data: 'no'
                }]
            }
            const adaptiveCard = new AdaptiveCards.AdaptiveCard();
            adaptiveCard.parse(card);
            const renderedCard = adaptiveCard.render();
            return {
                render: () => renderedCard,
                getAnswer: () => new Promise((resolve) => {
                    adaptiveCard.onExecuteAction = (action) => {
                        renderedCard.parentNode.removeChild(renderedCard)
                        resolve(action.data === 'yes')
                    }
                })
            }
        }

        function questionCard(question, answers = [], defaultValue = "") {
            const card = {
                type: 'AdaptiveCard',
                version: '1.5',
                body: [{
                    type: 'TextBlock',
                    text: question,
                    wrap: true
                }],
                actions: answers.filter(answer => answer && answer.trim()).map(answer => ({
                    type: 'Action.Submit',
                    title: answer,
                    data: answer
                }))
            }
            if (card.actions.length == 0) {
                card.body.push({
                    type: "Input.Text",
                    id: "answer",
                    label: "Answer",
                    value: defaultValue,
                    isMultiline: question.indexOf('prompt') > -1
                });
                card.actions.push({
                    type: 'Action.Submit',
                    title: 'Save'
                });
            }
            const adaptiveCard = new AdaptiveCards.AdaptiveCard();
            adaptiveCard.parse(card);
            const renderedCard = adaptiveCard.render();
            return {
                render: () => renderedCard,
                getAnswer: () => new Promise((resolve) => {
                    adaptiveCard.onExecuteAction = (action) => {
                        renderedCard.parentNode.removeChild(renderedCard)
                        if (action.data === '_cancel_' || (typeof action.data === 'object' && !action.data.answer)) {
                            resolve()
                        } else if (typeof action.data === 'object') {
                            resolve(action.data.answer)
                        } else {
                            resolve(action.data)
                        }
                    }
                })
            }
        }

        async function getConfig(option, text = `Enter the value for ${option}:`, defaultValue = undefined) {
            const value = getQueryString(option) || localStorage.getItem(option)
            if (value) return value
            const question = questionCard(text, undefined, defaultValue)
            outputContainer.appendChild(question.render())
            const answer = await question.getAnswer()
            if (answer) {
                localStorage.setItem(option, answer)
                return answer
            }
        }

        function getQueryString(key) {
            var urlParams = new URLSearchParams(window.location.search)
            return urlParams.get(key)
        }

        function useMarkdownRenderer(render) {
            AdaptiveCards.AdaptiveCard.onProcessMarkdown = function (text, result) {
                result.outputHtml = render(text);
                result.didProcess = true;
            };
        }
    </script>
</body>

</html>